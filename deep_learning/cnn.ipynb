{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Layer 1.\n",
    "filter_size1 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters1 = 16         # There are 16 of these filters.\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters2 = 36         # There are 36 of these filters.\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 128             # Number of neurons in fully-connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-f165911ebcd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/features_cnn/X_tr.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/features_cnn/X_te.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/features_cnn/Y_tr.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/features_cnn/Y_te.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding)\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0;31m# converting the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_loadtxt_chunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(chunk_size)\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mfloatconv\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'0x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromhex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[0mtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_tr = np.loadtxt(\"../data/features_cnn/X_tr.txt\")\n",
    "X_te = np.loadtxt(\"../data/features_cnn/X_te.txt\")\n",
    "\n",
    "y_tr = np.loadtxt(\"../data/features_cnn/Y_tr.txt\", dtype=int)\n",
    "y_te = np.loadtxt(\"../data/features_cnn/Y_te.txt\", dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_tr2 = X_tr[(y_tr==0) | (y_tr==2) | (y_tr==5) | (y_tr==8)]\n",
    "y_tr2 = y_tr[(y_tr==0) | (y_tr==2) | (y_tr==5) | (y_tr==8)]\n",
    "X_te2 = X_te[(y_te==0) | (y_te==2) | (y_te==5) | (y_te==8)]\n",
    "y_te2 = y_te[(y_te==0) | (y_te==2) | (y_te==5) | (y_te==8)]\n",
    "\n",
    "y_tr2[(y_tr2==2)] = 0\n",
    "y_tr2[(y_tr2==5) | (y_tr2==8)] = 1\n",
    "\n",
    "y_te2[(y_te2==2)] = 0\n",
    "y_te2[(y_te2==5) | (y_te2==8)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arr(y):\n",
    "    y_arr = np.zeros((y.shape[0], class_num))\n",
    "    for i in range(y.shape[0]):\n",
    "        val = y[i]\n",
    "        arr = np.zeros((class_num))\n",
    "        arr[val] = 1\n",
    "        y_arr[i,:] = arr\n",
    "    return y_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 6 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-5f903a0aa96c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_tr_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_arr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_te_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_arr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-152-795bbd79767f>\u001b[0m in \u001b[0;36mget_arr\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0my_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 6 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "y_tr_arr = get_arr(y_tr)\n",
    "y_te_arr = get_arr(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_arr2 = get_arr(y_tr2)\n",
    "y_te_arr2 = get_arr(y_te2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4105, 9)\n",
      "(1760, 9)\n",
      "(2068, 2)\n",
      "(911, 2)\n"
     ]
    }
   ],
   "source": [
    "print(y_tr_arr.shape)\n",
    "print(y_te_arr.shape)\n",
    "\n",
    "print(y_tr_arr2.shape)\n",
    "print(y_te_arr2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(y_tr_arr[0])\n",
    "print(y_tr[0])\n",
    "print(y_te_arr[0])\n",
    "print(y_te[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2068, 100, 100, 3)\n",
      "(911, 100, 100, 3)\n",
      "(2068,)\n",
      "(495,)\n"
     ]
    }
   ],
   "source": [
    "print(X_tr2.shape)\n",
    "print(X_te2.shape)\n",
    "print(y_tr2.shape)\n",
    "print(y_tr2[(y_tr2==0)].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = np.reshape(X_tr, (-1, 100, 100, 3))\n",
    "X_te = np.reshape(X_te, (-1, 100, 100, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4105, 100, 100, 3)\n",
      "(1760, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_tr.shape)\n",
    "print(X_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4105,)\n",
      "(1760,)\n"
     ]
    }
   ],
   "source": [
    "print(y_tr.shape)\n",
    "print(y_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know that  images are 100 pixels in each dimension.\n",
    "img_size = 100\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = img_size * img_size\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "# Number of colour channels for the images: 1 channel for gray-scale.\n",
    "num_channels = 3\n",
    "\n",
    "# Number of classes, one class for each of 10 digits.\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_conv_layer(input,              # The previous layer.\n",
    "                   num_input_channels, # Num. channels in prev. layer.\n",
    "                   filter_size,        # Width and height of each filter.\n",
    "                   num_filters,        # Number of filters.\n",
    "                   use_pooling=True):  # Use 2x2 max-pooling.\n",
    "\n",
    "    # Shape of the filter-weights for the convolution.\n",
    "    # This format is determined by the TensorFlow API.\n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "    # Create new weights aka. filters with the given shape.\n",
    "    weights = new_weights(shape=shape)\n",
    "\n",
    "    # Create new biases, one for each filter.\n",
    "    biases = new_biases(length=num_filters)\n",
    "\n",
    "    # Create the TensorFlow operation for convolution.\n",
    "    # Note the strides are set to 1 in all dimensions.\n",
    "    # The first and last stride must always be 1,\n",
    "    # because the first is for the image-number and\n",
    "    # the last is for the input-channel.\n",
    "    # But e.g. strides=[1, 2, 2, 1] would mean that the filter\n",
    "    # is moved 2 pixels across the x- and y-axis of the image.\n",
    "    # The padding is set to 'SAME' which means the input image\n",
    "    # is padded with zeroes so the size of the output is the same.\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                         filter=weights,\n",
    "                         strides=[1, 1, 1, 1],\n",
    "                         padding='SAME')\n",
    "\n",
    "    # Add the biases to the results of the convolution.\n",
    "    # A bias-value is added to each filter-channel.\n",
    "    layer += biases\n",
    "\n",
    "    # Use pooling to down-sample the image resolution?\n",
    "    if use_pooling:\n",
    "        # This is 2x2 max-pooling, which means that we\n",
    "        # consider 2x2 windows and select the largest value\n",
    "        # in each window. Then we move 2 pixels to the next window.\n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME')\n",
    "\n",
    "    # Rectified Linear Unit (ReLU).\n",
    "    # It calculates max(x, 0) for each input pixel x.\n",
    "    # This adds some non-linearity to the formula and allows us\n",
    "    # to learn more complicated functions.\n",
    "    layer = tf.nn.relu(layer)\n",
    "\n",
    "    # Note that ReLU is normally executed before the pooling,\n",
    "    # but since relu(max_pool(x)) == max_pool(relu(x)) we can\n",
    "    # save 75% of the relu-operations by max-pooling first.\n",
    "\n",
    "    # We return both the resulting layer and the filter-weights\n",
    "    # because we will plot the weights later.\n",
    "    return layer, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_layer(layer):\n",
    "    # Get the shape of the input layer.\n",
    "    layer_shape = layer.get_shape()\n",
    "\n",
    "    # The shape of the input layer is assumed to be:\n",
    "    # layer_shape == [num_images, img_height, img_width, num_channels]\n",
    "\n",
    "    # The number of features is: img_height * img_width * num_channels\n",
    "    # We can use a function from TensorFlow to calculate this.\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    \n",
    "    # Reshape the layer to [num_images, num_features].\n",
    "    # Note that we just set the size of the second dimension\n",
    "    # to num_features and the size of the first dimension to -1\n",
    "    # which means the size in that dimension is calculated\n",
    "    # so the total size of the tensor is unchanged from the reshaping.\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "\n",
    "    # The shape of the flattened layer is now:\n",
    "    # [num_images, img_height * img_width * num_channels]\n",
    "\n",
    "    # Return both the flattened layer and the number of features.\n",
    "    return layer_flat, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_fc_layer(input,          # The previous layer.\n",
    "                 num_inputs,     # Num. inputs from prev. layer.\n",
    "                 num_outputs,    # Num. outputs.\n",
    "                 use_relu=True): # Use Rectified Linear Unit (ReLU)?\n",
    "\n",
    "    # Create new weights and biases.\n",
    "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = new_biases(length=num_outputs)\n",
    "\n",
    "    # Calculate the layer as the matrix multiplication of\n",
    "    # the input and weights, and then add the bias-values.\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "\n",
    "    # Use ReLU?\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size, img_size, num_channels], name='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_cls = tf.argmax(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Layer 1\n",
    "\n",
    "layer_conv1, weights_conv1 = \\\n",
    "    new_conv_layer(input=x,\n",
    "                   num_input_channels=num_channels,\n",
    "                   filter_size=filter_size1,\n",
    "                   num_filters=num_filters1,\n",
    "                   use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_6:0' shape=(?, 50, 50, 16) dtype=float32>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Convolutional Layer 2\n",
    "\n",
    "layer_conv2, weights_conv2 = \\\n",
    "    new_conv_layer(input=layer_conv1,\n",
    "                   num_input_channels=num_filters1,\n",
    "                   filter_size=filter_size2,\n",
    "                   num_filters=num_filters2,\n",
    "                   use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_7:0' shape=(?, 25, 25, 36) dtype=float32>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_flat, num_features = flatten_layer(layer_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_2:0' shape=(?, 22500) dtype=float32>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22500"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully-Connected Layer 1\n",
    "\n",
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_8:0' shape=(?, 128) dtype=float32>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully-Connected Layer 2\n",
    "layer_fc2 = new_fc_layer(input=layer_fc1,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=num_classes,\n",
    "                         use_relu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_11:0' shape=(?, 2) dtype=float32>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(layer_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cls = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=layer_fc2,\n",
    "                                                        labels=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = data[idx]\n",
    "    labels_shuffle = labels[idx]\n",
    "\n",
    "    return data_shuffle, labels_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter for total number of iterations performed so far.\n",
    "total_iterations = 0\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    # Ensure we update the global variable rather than a local copy.\n",
    "    global total_iterations\n",
    "\n",
    "    # Start-time used for printing time-usage below.\n",
    "    start_time = time.time()\n",
    "    \n",
    "    acc_total = 0\n",
    "    count = 0\n",
    "\n",
    "    for i in range(total_iterations,\n",
    "                   total_iterations + num_iterations):\n",
    "\n",
    "        # Get a batch of training examples.\n",
    "        # x_batch now holds a batch of images and\n",
    "        # y_true_batch are the true labels for those images.\n",
    "        \n",
    "        x_batch, y_true_batch = next_batch(train_batch_size, X_tr2, y_tr_arr2)\n",
    "\n",
    "        # Put the batch into a dict with the proper names\n",
    "        # for placeholder variables in the TensorFlow graph.\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "\n",
    "        # Run the optimizer using this batch of training data.\n",
    "        # TensorFlow assigns the variables in feed_dict_train\n",
    "        # to the placeholder variables and then runs the optimizer.\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "        \n",
    "        acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "        acc_total += acc\n",
    "        count += 1\n",
    "        # Print status every 10 iterations.\n",
    "        if i % 50 == 0:\n",
    "            # Calculate the accuracy on the training-set.\n",
    "            \n",
    "            acc_ave = acc_total / count\n",
    "            acc_total = 0\n",
    "            count = 0\n",
    "            \n",
    "            # Message for printing.\n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "\n",
    "            # Print it.\n",
    "            print(msg.format(i + 1, acc_ave))\n",
    "\n",
    "    # Update the total number of iterations performed.\n",
    "    total_iterations += num_iterations\n",
    "\n",
    "    # Ending time.\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test-set into smaller batches of this size.\n",
    "test_batch_size = 128\n",
    "\n",
    "def print_test_accuracy(show_example_errors=False,\n",
    "                        show_confusion_matrix=False):\n",
    "\n",
    "    # Number of images in the test-set.\n",
    "    num_test = X_te2.shape[0]\n",
    "\n",
    "    # Allocate an array for the predicted classes which\n",
    "    # will be calculated in batches and filled into this array.\n",
    "    cls_pred = np.zeros(shape=num_test, dtype=np.int)\n",
    "\n",
    "    # Now calculate the predicted classes for the batches.\n",
    "    # We will just iterate through all the batches.\n",
    "    # There might be a more clever and Pythonic way of doing this.\n",
    "\n",
    "    # The starting index for the next batch is denoted i.\n",
    "    i = 0\n",
    "\n",
    "    while i < num_test:\n",
    "        # The ending index for the next batch is denoted j.\n",
    "        j = min(i + test_batch_size, num_test)\n",
    "\n",
    "        # Get the images from the test-set between index i and j.\n",
    "        images = X_te2[i:j, :]\n",
    "\n",
    "        # Get the associated labels.\n",
    "        labels = y_te_arr2[i:j, :]\n",
    "\n",
    "        # Create a feed-dict with these images and labels.\n",
    "        feed_dict = {x: images,\n",
    "                     y_true: labels}\n",
    "\n",
    "        # Calculate the predicted class using TensorFlow.\n",
    "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
    "\n",
    "        # Set the start-index for the next batch to the\n",
    "        # end-index of the current batch.\n",
    "        i = j\n",
    "\n",
    "    # Convenience variable for the true class-numbers of the test-set.\n",
    "    cls_true = y_te2\n",
    "\n",
    "    # Create a boolean array whether each image is correctly classified.\n",
    "    correct = (cls_true == cls_pred)\n",
    "\n",
    "    # Calculate the number of correctly classified images.\n",
    "    # When summing a boolean array, False means 0 and True means 1.\n",
    "    correct_sum = correct.sum()\n",
    "\n",
    "    # Classification accuracy is the number of correctly classified\n",
    "    # images divided by the total number of images in the test-set.\n",
    "    acc = float(correct_sum) / num_test\n",
    "\n",
    "    # Print the accuracy.\n",
    "    msg = \"Accuracy on Test-Set: {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(acc, correct_sum, num_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 76.0% (692 / 911)\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:      1, Training Accuracy:  85.9%\n",
      "Optimization Iteration:     51, Training Accuracy:  85.2%\n",
      "Optimization Iteration:    101, Training Accuracy:  87.2%\n",
      "Optimization Iteration:    151, Training Accuracy:  86.1%\n",
      "Optimization Iteration:    201, Training Accuracy:  86.7%\n",
      "Optimization Iteration:    251, Training Accuracy:  88.2%\n",
      "Optimization Iteration:    301, Training Accuracy:  89.0%\n",
      "Optimization Iteration:    351, Training Accuracy:  91.0%\n",
      "Optimization Iteration:    401, Training Accuracy:  89.3%\n",
      "Optimization Iteration:    451, Training Accuracy:  91.9%\n",
      "Optimization Iteration:    501, Training Accuracy:  93.1%\n",
      "Optimization Iteration:    551, Training Accuracy:  92.1%\n",
      "Optimization Iteration:    601, Training Accuracy:  93.0%\n",
      "Optimization Iteration:    651, Training Accuracy:  92.5%\n",
      "Optimization Iteration:    701, Training Accuracy:  92.4%\n",
      "Optimization Iteration:    751, Training Accuracy:  93.3%\n",
      "Optimization Iteration:    801, Training Accuracy:  93.6%\n",
      "Optimization Iteration:    851, Training Accuracy:  93.9%\n",
      "Optimization Iteration:    901, Training Accuracy:  94.7%\n",
      "Optimization Iteration:    951, Training Accuracy:  95.2%\n",
      "Optimization Iteration:   1001, Training Accuracy:  94.0%\n",
      "Optimization Iteration:   1051, Training Accuracy:  95.2%\n",
      "Optimization Iteration:   1101, Training Accuracy:  95.9%\n",
      "Optimization Iteration:   1151, Training Accuracy:  96.2%\n",
      "Optimization Iteration:   1201, Training Accuracy:  96.1%\n",
      "Optimization Iteration:   1251, Training Accuracy:  96.8%\n",
      "Optimization Iteration:   1301, Training Accuracy:  97.5%\n",
      "Optimization Iteration:   1351, Training Accuracy:  97.2%\n",
      "Optimization Iteration:   1401, Training Accuracy:  97.3%\n",
      "Optimization Iteration:   1451, Training Accuracy:  97.9%\n",
      "Optimization Iteration:   1501, Training Accuracy:  98.1%\n",
      "Optimization Iteration:   1551, Training Accuracy:  98.9%\n",
      "Optimization Iteration:   1601, Training Accuracy:  98.2%\n",
      "Optimization Iteration:   1651, Training Accuracy:  98.1%\n",
      "Optimization Iteration:   1701, Training Accuracy:  98.6%\n",
      "Optimization Iteration:   1751, Training Accuracy:  98.8%\n",
      "Optimization Iteration:   1801, Training Accuracy:  99.1%\n",
      "Optimization Iteration:   1851, Training Accuracy:  98.9%\n",
      "Optimization Iteration:   1901, Training Accuracy:  99.2%\n",
      "Optimization Iteration:   1951, Training Accuracy:  98.7%\n",
      "Optimization Iteration:   2001, Training Accuracy:  99.3%\n",
      "Optimization Iteration:   2051, Training Accuracy:  99.2%\n",
      "Optimization Iteration:   2101, Training Accuracy:  99.4%\n",
      "Optimization Iteration:   2151, Training Accuracy:  99.3%\n",
      "Optimization Iteration:   2201, Training Accuracy:  99.6%\n",
      "Optimization Iteration:   2251, Training Accuracy:  99.8%\n",
      "Optimization Iteration:   2301, Training Accuracy:  99.8%\n",
      "Optimization Iteration:   2351, Training Accuracy:  99.8%\n",
      "Optimization Iteration:   2401, Training Accuracy:  99.3%\n",
      "Optimization Iteration:   2451, Training Accuracy:  99.8%\n",
      "Optimization Iteration:   2501, Training Accuracy:  99.8%\n",
      "Optimization Iteration:   2551, Training Accuracy:  99.9%\n",
      "Optimization Iteration:   2601, Training Accuracy:  99.6%\n",
      "Optimization Iteration:   2651, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   2701, Training Accuracy:  99.9%\n",
      "Optimization Iteration:   2751, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   2801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   2851, Training Accuracy:  99.9%\n",
      "Optimization Iteration:   2901, Training Accuracy:  99.9%\n",
      "Optimization Iteration:   2951, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3051, Training Accuracy:  99.9%\n",
      "Optimization Iteration:   3101, Training Accuracy:  99.7%\n",
      "Optimization Iteration:   3151, Training Accuracy:  99.6%\n",
      "Optimization Iteration:   3201, Training Accuracy:  99.9%\n",
      "Optimization Iteration:   3251, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3351, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3451, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3551, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3651, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3751, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3851, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3951, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4051, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4151, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4251, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4351, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4451, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4551, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4651, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4751, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4851, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4951, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5051, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5151, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5251, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5351, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5451, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5551, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5651, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5751, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5851, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5951, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6051, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6151, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6251, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6351, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6451, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6551, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6651, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6751, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6851, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6951, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7051, Training Accuracy: 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   7101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7151, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7251, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7351, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7451, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7551, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7651, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7751, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7851, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7951, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8051, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8151, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8251, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8351, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8451, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8551, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8651, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8751, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8851, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8951, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9051, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9151, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9251, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9351, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9451, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9551, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9651, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9751, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9851, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9951, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10051, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10151, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10251, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10351, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10451, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10551, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10651, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10751, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10851, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10951, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11051, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11151, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11251, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11301, Training Accuracy:  94.2%\n",
      "Optimization Iteration:  11351, Training Accuracy:  96.9%\n",
      "Optimization Iteration:  11401, Training Accuracy:  99.8%\n",
      "Optimization Iteration:  11451, Training Accuracy:  99.9%\n",
      "Optimization Iteration:  11501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11551, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11651, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11751, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11851, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11951, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12051, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12151, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12251, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12351, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12451, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12551, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12651, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12751, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12851, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12951, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13051, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13151, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13251, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13351, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13451, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13551, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13651, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13751, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13851, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13951, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14051, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14151, Training Accuracy: 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  14201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14251, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14351, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14451, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14551, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14651, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14751, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14801, Training Accuracy: 100.0%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-223-cccd8b8fd52d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-219-458835f541a0>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(num_iterations)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# TensorFlow assigns the variables in feed_dict_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# to the placeholder variables and then runs the optimizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimize(num_iterations=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 87.7% (799 / 911)\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
