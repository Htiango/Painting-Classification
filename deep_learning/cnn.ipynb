{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Layer 1.\n",
    "filter_size1 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters1 = 16         # There are 16 of these filters.\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters2 = 36         # There are 36 of these filters.\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 128             # Number of neurons in fully-connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-f165911ebcd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/features_cnn/X_tr.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/features_cnn/X_te.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/features_cnn/Y_tr.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/features_cnn/Y_te.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding)\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0;31m# converting the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_loadtxt_chunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(chunk_size)\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mfloatconv\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'0x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromhex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[0mtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_tr = np.loadtxt(\"../data/features_cnn/X_tr.txt\")\n",
    "X_te = np.loadtxt(\"../data/features_cnn/X_te.txt\")\n",
    "\n",
    "y_tr = np.loadtxt(\"../data/features_cnn/Y_tr.txt\", dtype=int)\n",
    "y_te = np.loadtxt(\"../data/features_cnn/Y_te.txt\", dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_tr2 = X_tr[(y_tr==0) | (y_tr==2) | (y_tr==5) | (y_tr==8)]\n",
    "y_tr2 = y_tr[(y_tr==0) | (y_tr==2) | (y_tr==5) | (y_tr==8)]\n",
    "X_te2 = X_te[(y_te==0) | (y_te==2) | (y_te==5) | (y_te==8)]\n",
    "y_te2 = y_te[(y_te==0) | (y_te==2) | (y_te==5) | (y_te==8)]\n",
    "\n",
    "y_tr2[(y_tr2==2)] = 0\n",
    "y_tr2[(y_tr2==5) | (y_tr2==8)] = 1\n",
    "\n",
    "y_te2[(y_te2==2)] = 0\n",
    "y_te2[(y_te2==5) | (y_te2==8)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arr(y):\n",
    "    y_arr = np.zeros((y.shape[0], class_num))\n",
    "    for i in range(y.shape[0]):\n",
    "        val = y[i]\n",
    "        arr = np.zeros((class_num))\n",
    "        arr[val] = 1\n",
    "        y_arr[i,:] = arr\n",
    "    return y_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 6 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-5f903a0aa96c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_tr_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_arr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_te_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_arr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-152-795bbd79767f>\u001b[0m in \u001b[0;36mget_arr\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0my_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 6 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "y_tr_arr = get_arr(y_tr)\n",
    "y_te_arr = get_arr(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_arr2 = get_arr(y_tr2)\n",
    "y_te_arr2 = get_arr(y_te2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4105, 9)\n",
      "(1760, 9)\n",
      "(2068, 2)\n",
      "(911, 2)\n"
     ]
    }
   ],
   "source": [
    "print(y_tr_arr.shape)\n",
    "print(y_te_arr.shape)\n",
    "\n",
    "print(y_tr_arr2.shape)\n",
    "print(y_te_arr2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(y_tr_arr[0])\n",
    "print(y_tr[0])\n",
    "print(y_te_arr[0])\n",
    "print(y_te[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2068, 100, 100, 3)\n",
      "(911, 100, 100, 3)\n",
      "(2068,)\n",
      "(495,)\n"
     ]
    }
   ],
   "source": [
    "print(X_tr2.shape)\n",
    "print(X_te2.shape)\n",
    "print(y_tr2.shape)\n",
    "print(y_tr2[(y_tr2==0)].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = np.reshape(X_tr, (-1, 100, 100, 3))\n",
    "X_te = np.reshape(X_te, (-1, 100, 100, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4105, 100, 100, 3)\n",
      "(1760, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_tr.shape)\n",
    "print(X_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4105,)\n",
      "(1760,)\n"
     ]
    }
   ],
   "source": [
    "print(y_tr.shape)\n",
    "print(y_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know that  images are 100 pixels in each dimension.\n",
    "img_size = 100\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = img_size * img_size\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "# Number of colour channels for the images: 1 channel for gray-scale.\n",
    "num_channels = 3\n",
    "\n",
    "# Number of classes, one class for each of 10 digits.\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_conv_layer(input,              # The previous layer.\n",
    "                   num_input_channels, # Num. channels in prev. layer.\n",
    "                   filter_size,        # Width and height of each filter.\n",
    "                   num_filters,        # Number of filters.\n",
    "                   use_pooling=True):  # Use 2x2 max-pooling.\n",
    "\n",
    "    # Shape of the filter-weights for the convolution.\n",
    "    # This format is determined by the TensorFlow API.\n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "    # Create new weights aka. filters with the given shape.\n",
    "    weights = new_weights(shape=shape)\n",
    "\n",
    "    # Create new biases, one for each filter.\n",
    "    biases = new_biases(length=num_filters)\n",
    "\n",
    "    # Create the TensorFlow operation for convolution.\n",
    "    # Note the strides are set to 1 in all dimensions.\n",
    "    # The first and last stride must always be 1,\n",
    "    # because the first is for the image-number and\n",
    "    # the last is for the input-channel.\n",
    "    # But e.g. strides=[1, 2, 2, 1] would mean that the filter\n",
    "    # is moved 2 pixels across the x- and y-axis of the image.\n",
    "    # The padding is set to 'SAME' which means the input image\n",
    "    # is padded with zeroes so the size of the output is the same.\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                         filter=weights,\n",
    "                         strides=[1, 1, 1, 1],\n",
    "                         padding='SAME')\n",
    "\n",
    "    # Add the biases to the results of the convolution.\n",
    "    # A bias-value is added to each filter-channel.\n",
    "    layer += biases\n",
    "\n",
    "    # Use pooling to down-sample the image resolution?\n",
    "    if use_pooling:\n",
    "        # This is 2x2 max-pooling, which means that we\n",
    "        # consider 2x2 windows and select the largest value\n",
    "        # in each window. Then we move 2 pixels to the next window.\n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME')\n",
    "\n",
    "    # Rectified Linear Unit (ReLU).\n",
    "    # It calculates max(x, 0) for each input pixel x.\n",
    "    # This adds some non-linearity to the formula and allows us\n",
    "    # to learn more complicated functions.\n",
    "    layer = tf.nn.relu(layer)\n",
    "\n",
    "    # Note that ReLU is normally executed before the pooling,\n",
    "    # but since relu(max_pool(x)) == max_pool(relu(x)) we can\n",
    "    # save 75% of the relu-operations by max-pooling first.\n",
    "\n",
    "    # We return both the resulting layer and the filter-weights\n",
    "    # because we will plot the weights later.\n",
    "    return layer, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_layer(layer):\n",
    "    # Get the shape of the input layer.\n",
    "    layer_shape = layer.get_shape()\n",
    "\n",
    "    # The shape of the input layer is assumed to be:\n",
    "    # layer_shape == [num_images, img_height, img_width, num_channels]\n",
    "\n",
    "    # The number of features is: img_height * img_width * num_channels\n",
    "    # We can use a function from TensorFlow to calculate this.\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    \n",
    "    # Reshape the layer to [num_images, num_features].\n",
    "    # Note that we just set the size of the second dimension\n",
    "    # to num_features and the size of the first dimension to -1\n",
    "    # which means the size in that dimension is calculated\n",
    "    # so the total size of the tensor is unchanged from the reshaping.\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "\n",
    "    # The shape of the flattened layer is now:\n",
    "    # [num_images, img_height * img_width * num_channels]\n",
    "\n",
    "    # Return both the flattened layer and the number of features.\n",
    "    return layer_flat, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_fc_layer(input,          # The previous layer.\n",
    "                 num_inputs,     # Num. inputs from prev. layer.\n",
    "                 num_outputs,    # Num. outputs.\n",
    "                 use_relu=True): # Use Rectified Linear Unit (ReLU)?\n",
    "\n",
    "    # Create new weights and biases.\n",
    "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = new_biases(length=num_outputs)\n",
    "\n",
    "    # Calculate the layer as the matrix multiplication of\n",
    "    # the input and weights, and then add the bias-values.\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "\n",
    "    # Use ReLU?\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size, img_size, num_channels], name='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_cls = tf.argmax(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Layer 1\n",
    "\n",
    "layer_conv1, weights_conv1 = \\\n",
    "    new_conv_layer(input=x,\n",
    "                   num_input_channels=num_channels,\n",
    "                   filter_size=filter_size1,\n",
    "                   num_filters=num_filters1,\n",
    "                   use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_6:0' shape=(?, 50, 50, 16) dtype=float32>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Convolutional Layer 2\n",
    "\n",
    "layer_conv2, weights_conv2 = \\\n",
    "    new_conv_layer(input=layer_conv1,\n",
    "                   num_input_channels=num_filters1,\n",
    "                   filter_size=filter_size2,\n",
    "                   num_filters=num_filters2,\n",
    "                   use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_7:0' shape=(?, 25, 25, 36) dtype=float32>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_flat, num_features = flatten_layer(layer_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_2:0' shape=(?, 22500) dtype=float32>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22500"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully-Connected Layer 1\n",
    "\n",
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_8:0' shape=(?, 128) dtype=float32>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully-Connected Layer 2\n",
    "layer_fc2 = new_fc_layer(input=layer_fc1,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=num_classes,\n",
    "                         use_relu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_11:0' shape=(?, 2) dtype=float32>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(layer_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cls = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=layer_fc2,\n",
    "                                                        labels=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = data[idx]\n",
    "    labels_shuffle = labels[idx]\n",
    "\n",
    "    return data_shuffle, labels_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter for total number of iterations performed so far.\n",
    "total_iterations = 0\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    # Ensure we update the global variable rather than a local copy.\n",
    "    global total_iterations\n",
    "\n",
    "    # Start-time used for printing time-usage below.\n",
    "    start_time = time.time()\n",
    "    \n",
    "    acc_total = 0\n",
    "    count = 0\n",
    "\n",
    "    for i in range(total_iterations,\n",
    "                   total_iterations + num_iterations):\n",
    "\n",
    "        # Get a batch of training examples.\n",
    "        # x_batch now holds a batch of images and\n",
    "        # y_true_batch are the true labels for those images.\n",
    "        \n",
    "        x_batch, y_true_batch = next_batch(train_batch_size, X_tr2, y_tr_arr2)\n",
    "\n",
    "        # Put the batch into a dict with the proper names\n",
    "        # for placeholder variables in the TensorFlow graph.\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "\n",
    "        # Run the optimizer using this batch of training data.\n",
    "        # TensorFlow assigns the variables in feed_dict_train\n",
    "        # to the placeholder variables and then runs the optimizer.\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "        \n",
    "        acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "        acc_total += acc\n",
    "        count += 1\n",
    "        # Print status every 10 iterations.\n",
    "        if i % 50 == 0:\n",
    "            # Calculate the accuracy on the training-set.\n",
    "            \n",
    "            acc_ave = acc_total / count\n",
    "            acc_total = 0\n",
    "            count = 0\n",
    "            \n",
    "            # Message for printing.\n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "\n",
    "            # Print it.\n",
    "            print(msg.format(i + 1, acc_ave))\n",
    "\n",
    "    # Update the total number of iterations performed.\n",
    "    total_iterations += num_iterations\n",
    "\n",
    "    # Ending time.\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test-set into smaller batches of this size.\n",
    "test_batch_size = 128\n",
    "\n",
    "def print_test_accuracy(show_confusion_matrix=False):\n",
    "\n",
    "    # Number of images in the test-set.\n",
    "    num_test = X_te2.shape[0]\n",
    "\n",
    "    # Allocate an array for the predicted classes which\n",
    "    # will be calculated in batches and filled into this array.\n",
    "    cls_pred = np.zeros(shape=num_test, dtype=np.int)\n",
    "\n",
    "    # Now calculate the predicted classes for the batches.\n",
    "    # We will just iterate through all the batches.\n",
    "    # There might be a more clever and Pythonic way of doing this.\n",
    "\n",
    "    # The starting index for the next batch is denoted i.\n",
    "    i = 0\n",
    "\n",
    "    while i < num_test:\n",
    "        # The ending index for the next batch is denoted j.\n",
    "        j = min(i + test_batch_size, num_test)\n",
    "\n",
    "        # Get the images from the test-set between index i and j.\n",
    "        images = X_te2[i:j, :]\n",
    "\n",
    "        # Get the associated labels.\n",
    "        labels = y_te_arr2[i:j, :]\n",
    "\n",
    "        # Create a feed-dict with these images and labels.\n",
    "        feed_dict = {x: images,\n",
    "                     y_true: labels}\n",
    "\n",
    "        # Calculate the predicted class using TensorFlow.\n",
    "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
    "\n",
    "        # Set the start-index for the next batch to the\n",
    "        # end-index of the current batch.\n",
    "        i = j\n",
    "\n",
    "    # Convenience variable for the true class-numbers of the test-set.\n",
    "    cls_true = y_te2\n",
    "\n",
    "    # Create a boolean array whether each image is correctly classified.\n",
    "    correct = (cls_true == cls_pred)\n",
    "\n",
    "    # Calculate the number of correctly classified images.\n",
    "    # When summing a boolean array, False means 0 and True means 1.\n",
    "    correct_sum = correct.sum()\n",
    "\n",
    "    # Classification accuracy is the number of correctly classified\n",
    "    # images divided by the total number of images in the test-set.\n",
    "    acc = float(correct_sum) / num_test\n",
    "\n",
    "    # Print the accuracy.\n",
    "    msg = \"Accuracy on Test-Set: {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(acc, correct_sum, num_test))\n",
    "\n",
    "    if show_confusion_matrix:\n",
    "        print(\"Confusion Matrix:\")\n",
    "        plot_confusion_matrix(cls_pred=cls_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 76.0% (692 / 911)\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:      1, Training Accuracy:  85.9%\n",
      "Optimization Iteration:     51, Training Accuracy:  85.2%\n",
      "Optimization Iteration:    101, Training Accuracy:  87.2%\n",
      "Optimization Iteration:    151, Training Accuracy:  86.1%\n",
      "Optimization Iteration:    201, Training Accuracy:  86.7%\n",
      "Optimization Iteration:    251, Training Accuracy:  88.2%\n",
      "Optimization Iteration:    301, Training Accuracy:  89.0%\n",
      "Optimization Iteration:    351, Training Accuracy:  91.0%\n",
      "Optimization Iteration:    401, Training Accuracy:  89.3%\n",
      "Optimization Iteration:    451, Training Accuracy:  91.9%\n",
      "Optimization Iteration:    501, Training Accuracy:  93.1%\n",
      "Optimization Iteration:    551, Training Accuracy:  92.1%\n",
      "Optimization Iteration:    601, Training Accuracy:  93.0%\n",
      "Optimization Iteration:    651, Training Accuracy:  92.5%\n",
      "Optimization Iteration:    701, Training Accuracy:  92.4%\n",
      "Optimization Iteration:    751, Training Accuracy:  93.3%\n",
      "Optimization Iteration:    801, Training Accuracy:  93.6%\n",
      "Optimization Iteration:    851, Training Accuracy:  93.9%\n",
      "Optimization Iteration:    901, Training Accuracy:  94.7%\n",
      "Optimization Iteration:    951, Training Accuracy:  95.2%\n",
      "Optimization Iteration:   1001, Training Accuracy:  94.0%\n",
      "Optimization Iteration:   1051, Training Accuracy:  95.2%\n",
      "Optimization Iteration:   1101, Training Accuracy:  95.9%\n",
      "Optimization Iteration:   1151, Training Accuracy:  96.2%\n",
      "Optimization Iteration:   1201, Training Accuracy:  96.1%\n",
      "Optimization Iteration:   1251, Training Accuracy:  96.8%\n",
      "Optimization Iteration:   1301, Training Accuracy:  97.5%\n",
      "Optimization Iteration:   1351, Training Accuracy:  97.2%\n",
      "Optimization Iteration:   1401, Training Accuracy:  97.3%\n",
      "Optimization Iteration:   1451, Training Accuracy:  97.9%\n",
      "Optimization Iteration:   1501, Training Accuracy:  98.1%\n",
      "Optimization Iteration:   1551, Training Accuracy:  98.9%\n",
      "Optimization Iteration:   1601, Training Accuracy:  98.2%\n",
      "Optimization Iteration:   1651, Training Accuracy:  98.1%\n",
      "Optimization Iteration:   1701, Training Accuracy:  98.6%\n",
      "Optimization Iteration:   1751, Training Accuracy:  98.8%\n",
      "Optimization Iteration:   1801, Training Accuracy:  99.1%\n",
      "Optimization Iteration:   1851, Training Accuracy:  98.9%\n",
      "Optimization Iteration:   1901, Training Accuracy:  99.2%\n",
      "Optimization Iteration:   1951, Training Accuracy:  98.7%\n",
      "Optimization Iteration:   2001, Training Accuracy:  99.3%\n",
      "Optimization Iteration:   2051, Training Accuracy:  99.2%\n",
      "Optimization Iteration:   2101, Training Accuracy:  99.4%\n",
      "Optimization Iteration:   2151, Training Accuracy:  99.3%\n",
      "Optimization Iteration:   2201, Training Accuracy:  99.6%\n",
      "Optimization Iteration:   2251, Training Accuracy:  99.8%\n",
      "Optimization Iteration:   2301, Training Accuracy:  99.8%\n",
      "Optimization Iteration:   2351, Training Accuracy:  99.8%\n",
      "Optimization Iteration:   2401, Training Accuracy:  99.3%\n",
      "Optimization Iteration:   2451, Training Accuracy:  99.8%\n",
      "Optimization Iteration:   2501, Training Accuracy:  99.8%\n",
      "Optimization Iteration:   2551, Training Accuracy:  99.9%\n",
      "Optimization Iteration:   2601, Training Accuracy:  99.6%\n",
      "Optimization Iteration:   2651, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   2701, Training Accuracy:  99.9%\n",
      "Optimization Iteration:   2751, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   2801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   2851, Training Accuracy:  99.9%\n",
      "Optimization Iteration:   2901, Training Accuracy:  99.9%\n",
      "Optimization Iteration:   2951, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3051, Training Accuracy:  99.9%\n",
      "Optimization Iteration:   3101, Training Accuracy:  99.7%\n",
      "Optimization Iteration:   3151, Training Accuracy:  99.6%\n",
      "Optimization Iteration:   3201, Training Accuracy:  99.9%\n",
      "Optimization Iteration:   3251, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3351, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3451, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3551, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3651, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3751, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3851, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3951, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4051, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4151, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4251, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4351, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4451, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4551, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4651, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4751, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4851, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4951, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5051, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5151, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5251, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5351, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5451, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5551, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5651, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5751, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5851, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5951, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6051, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6151, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6251, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6351, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6451, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6551, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6651, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6751, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6851, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   6951, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7051, Training Accuracy: 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:   7101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7151, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7251, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7351, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7451, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7551, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7651, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7751, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7851, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   7951, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8051, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8151, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8251, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8351, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8451, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8551, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8651, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8751, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8851, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8951, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9051, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9151, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9251, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9351, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9451, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9551, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9651, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9751, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9851, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9951, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10051, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10151, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10251, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10351, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10451, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10551, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10651, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10751, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10851, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  10951, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11051, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11151, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11251, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11301, Training Accuracy:  94.2%\n",
      "Optimization Iteration:  11351, Training Accuracy:  96.9%\n",
      "Optimization Iteration:  11401, Training Accuracy:  99.8%\n",
      "Optimization Iteration:  11451, Training Accuracy:  99.9%\n",
      "Optimization Iteration:  11501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11551, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11651, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11751, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11851, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  11951, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12051, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12151, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12251, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12351, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12451, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12551, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12651, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12751, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12851, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  12951, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13051, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13151, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13251, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13351, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13451, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13551, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13651, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13751, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13801, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13851, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  13951, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14051, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14101, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14151, Training Accuracy: 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:  14201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14251, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14351, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14451, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14551, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14651, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14751, Training Accuracy: 100.0%\n",
      "Optimization Iteration:  14801, Training Accuracy: 100.0%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-223-cccd8b8fd52d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-219-458835f541a0>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(num_iterations)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# TensorFlow assigns the variables in feed_dict_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# to the placeholder variables and then runs the optimizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimize(num_iterations=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 87.7% (799 / 911)\n",
      "Confusion Matrix:\n",
      "[[158  56]\n",
      " [ 56 641]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQwAAAD0CAYAAABuOhhTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYJhZNgcMM8vmgGFm2RwwzCzb/wGsZ6EtlYXgVwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122c626a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_test_accuracy(show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cls_pred):\n",
    "    # This is called from print_test_accuracy() below.\n",
    "\n",
    "    # cls_pred is an array of the predicted class-number for\n",
    "    # all images in the test-set.\n",
    "\n",
    "    # Get the true classifications for the test-set.\n",
    "    cls_true = y_te2\n",
    "    \n",
    "    # Get the confusion matrix using sklearn.\n",
    "    cm = confusion_matrix(y_true=cls_true,\n",
    "                          y_pred=cls_pred)\n",
    "\n",
    "    # Print the confusion matrix as text.\n",
    "    print(cm)\n",
    "\n",
    "    # Plot the confusion matrix as an image.\n",
    "    plt.matshow(cm)\n",
    "\n",
    "    # Make various adjustments to the plot.\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, range(num_classes))\n",
    "    plt.yticks(tick_marks, range(num_classes))\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "\n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
